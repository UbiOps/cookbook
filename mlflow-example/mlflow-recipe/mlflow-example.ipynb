{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow example\n",
    "\n",
    "Note: This notebook runs on Python 3.6 and uses UbiOps CLient Library 3.3.0.\n",
    "\n",
    "In this notebook we will show you the following:\n",
    "\n",
    "How to create a deployment that uses a model built and tracked using MLFlow which will help to find the optimal parameters, this model will use several features to predict the quality of wine.\n",
    "\n",
    "This example uses the a sample dataset from one of the examples on the MLFlow website. [Link to the dataset](https://github.com/mlflow/mlflow-example)\n",
    "\n",
    "\n",
    "If you run this entire notebook after filling in your access token, the mlflow deployment will be deployed to your UbiOps environment. You can thus check your environment after running to explore. You can also check the individual steps in this notebook to see what we did exactly and how you can adapt it to your own use case.\n",
    "\n",
    "We recommend to run the cells step by step, as some cells can take a few minutes to finish. You can run everything in one go as well and it will work, just allow a few minutes for building the individual deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required packages\n",
    "We will use several packages to create our model and deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "A model that looks at features of wine and tries to predict the quality based on that. This is based on the [Example from the MLFlow documentation](https://github.com/mlflow/mlflow-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load wine-model/train.py\n",
    "# The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "# P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "# Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for the most optimal parameters\n",
    "We can do this in one of two ways:\n",
    "* Manually via the command line\n",
    "* Programmatically using python\n",
    "\n",
    "We will use the latter in this example because it can be automated and would take less time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing best parameters\n",
    "We can also use the mlflow package to test a list of possible settings to see which performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'alpha': 0.3, 'l1_ratio': 0.1},\n",
    "    {'alpha': 0.2, 'l1_ratio': 0.7},\n",
    "    {'alpha': 0.4, 'l1_ratio': 0.2},\n",
    "    {'alpha': 0.5, 'l1_ratio': 0.7},\n",
    "    {'alpha': 0.1, 'l1_ratio': 0.9},\n",
    "    {'alpha': 0.2, 'l1_ratio': 0.2},\n",
    "    {'alpha': 0.7},\n",
    "]\n",
    "\n",
    "model_location = 'wine-model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "for param in parameters:\n",
    "    print(f'Running with param = {param}')\n",
    "    res = mlflow.run(model_location, parameters=param, use_conda=False)\n",
    "    print(f'status={res.get_status()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the results\n",
    "Start a terminal session and run this (in the mlflow-example folder). Then head over to [the MLFlow UI](http://localhost:5000)\n",
    "```\n",
    "mlflow ui\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparing runs](images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the optimal run\n",
    "\n",
    "After running you can view the runs of your model with the metrics of each time and compare to find the best configuration for use case.\n",
    "\n",
    "For my example I would like to use the model with the lowest root mean square error (RMSE), running the code in the cell below will find that run id and copy the built model into our deployment folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Reading Pandas Dataframe from mlflow\n",
    "df=mlflow.search_runs(filter_string=\"metrics.rmse < 1\")\n",
    "\n",
    "# Fetching Run ID for\n",
    "run = df.loc[df['metrics.rmse'].idxmin()]\n",
    "run_id = run['run_id']\n",
    "\n",
    "print(f'The optimal run id is {run_id}')\n",
    "print(f'It had the parameters: alpha={run[\"params.alpha\"]}, l1_ratio={run[\"params.l1_ratio\"]}')\n",
    "print(f'And RMSE: {run[\"metrics.rmse\"]}')\n",
    "\n",
    "\n",
    "copyStatus = copyfile(f'mlruns/0/{run_id}/artifacts/model/model.pkl', 'mlflow_deployment_package/model.pkl')\n",
    "print('Model copied to the deployment!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment steps\n",
    "Now that we have the optimal model copied into our deployment folder we will start the steps to deploy it to our UbiOps environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = \"<INSERT API_TOKEN WITH PROJECT EDITOR RIGHTS>\" # Make sure this is in the format \"Token token-code\"\n",
    "PROJECT_NAME = \"<INSERT PROJECT NAME IN YOUR ACCOUNT>\"\n",
    "DEPLOYMENT_NAME = 'mlflow-deployment'\n",
    "DEPLOYMENT_VERSION = 'v1'\n",
    "\n",
    "# Import all necessary libraries\n",
    "import shutil\n",
    "import os\n",
    "import ubiops\n",
    "\n",
    "client = ubiops.ApiClient(ubiops.Configuration(api_key={'Authorization': API_TOKEN}, \n",
    "                                               host='https://api.ubiops.com/v2.1'))\n",
    "api = ubiops.CoreApi(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mlflow_deployment_package/deployment.py\n",
    "\"\"\"\n",
    "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
    "class and 'request' method.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Deployment:\n",
    "\n",
    "    def __init__(self, base_directory, context):\n",
    "        \"\"\"\n",
    "        Initialisation method for the deployment. It can for example be used for loading modules that have to be kept in\n",
    "        memory or setting up connections. Load your external model files (such as pickles or .h5 files) here.\n",
    "\n",
    "        :param str base_directory: absolute path to the directory where the deployment.py file is located\n",
    "        :param dict context: a dictionary containing details of the deployment that might be useful in your code.\n",
    "            It contains the following keys:\n",
    "                - deployment (str): name of the deployment\n",
    "                - version (str): name of the version\n",
    "                - input_type (str): deployment input type, either 'structured' or 'plain'\n",
    "                - output_type (str): deployment output type, either 'structured' or 'plain'\n",
    "                - language (str): programming language the deployment is running\n",
    "                - environment_variables (str): the custom environment variables configured for the deployment.\n",
    "                    You can also access those as normal environment variables via os.environ\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Initialising the model\")\n",
    "\n",
    "        model_file = os.path.join(base_directory, \"model.pkl\")\n",
    "        with open('model.pkl', 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "\n",
    "\n",
    "    def request(self, data):\n",
    "        \"\"\"\n",
    "        Method for deployment requests, called separately for each individual request.\n",
    "\n",
    "        :param dict/str data: request input data. In case of deployments with structured data, a Python dictionary\n",
    "            with as keys the input fields as defined upon deployment creation via the platform. In case of a deployment\n",
    "            with plain input, it is a string.\n",
    "        :return dict/str: request output. In case of deployments with structured output data, a Python dictionary\n",
    "            with as keys the output fields as defined upon deployment creation via the platform. In case of a deployment\n",
    "            with plain output, it is a string. In this example, a dictionary with the key: output.\n",
    "        \"\"\"\n",
    "        print('Loading data')\n",
    "        input_data = pd.read_csv(data['data'])\n",
    "        \n",
    "        print(\"Prediction being made\")\n",
    "        prediction = self.model.predict(input_data)\n",
    "        \n",
    "        # Writing the prediction to a csv for further use\n",
    "        print('Writing prediction to csv')\n",
    "        pd.DataFrame(prediction).to_csv('prediction.csv', header = ['MPG'], index_label= 'index')\n",
    "        \n",
    "        return {\n",
    "            \"prediction\": 'prediction.csv',\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployment\n",
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    description='MLFlow deployment',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='data',\n",
    "            data_type='blob',\n",
    "        ),\n",
    "    ],\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='prediction',\n",
    "            data_type='blob'\n",
    "        ),\n",
    "    ],\n",
    "    labels={'demo': 'mlflow-recipe'}\n",
    ")\n",
    "\n",
    "api.deployments_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=deployment_template\n",
    ")\n",
    "\n",
    "# Create the version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    language='python3.6',\n",
    "    memory_allocation=512,\n",
    "    minimum_instances=0,\n",
    "    maximum_instances=1,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # We don't need to store the requests for this deployment    \n",
    ")\n",
    "\n",
    "api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    data=version_template\n",
    ")\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive('mlflow_deployment_package', 'zip', '.', 'mlflow_deployment_package')\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "file_upload_result =api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='mlflow_deployment_package.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a request and exploring further\n",
    "You can go ahead to the Web App and take a look in the user interface at what you have just built. If you want you can create a request to the mlflow deployment using the \"dummy_data_to_predict.csv\". The dummy data is just the horsepower data.\n",
    "\n",
    "So there we have it! We have created a deployment and using the mlfow tool tested the best parameters for it. You can use this notebook to base your own deployments on. Just adapt the code in the deployment packages and alter the input and output fields as you wish and you should be good to go.\n",
    "\n",
    "For any questions, feel free to reach out to us via the customer service portal: https://ubiops.atlassian.net/servicedesk/customer/portals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}