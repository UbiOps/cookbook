{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit template\n",
    "**Note**: This notebook runs on Python 3.6 and uses UbiOps CLient Library 3.3.0.\n",
    "\n",
    "In this notebook we will show you the following:\n",
    "- how to make a training pipeline in UbiOps which preprocesses the data and trains and tests a model using scikit\n",
    "- how to make a production pipeline in UbiOps which takes in new data, processes it and feeds it to a trained model for prediction/classification\n",
    "\n",
    "For this example we will use a diabetes dataset from Kaggle to create a KNN classifier to predict if someone will have diabetes or not. Link to original dataset: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "If you run this entire notebook after filling in your access token, the two pipelines and all the necessary models will be deployed to your UbiOps environment. You can thus check your environment after running to explore. You can also check the individual steps in this notebook to see what we did exactly and how you can adapt it to your own use case.\n",
    "\n",
    "We recommend to run the cells step by step, as some cells can take a few minutes to finish. You can run everything in one go as well and it will work, just allow a few minutes for building the individual deployments.\n",
    "\n",
    "## Establishing a connection with your UbiOps environment\n",
    "Add your API token. Then we will provide a project name, deployment name and deployment version name. Afterwards we initialize the client library. This way we can deploy the two pipelines to your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = \"<INSERT YOUR TOKEN HERE>\" # Make sure this is in the format \"Token token-code\"\n",
    "PROJECT_NAME = \"<INSERT PROJECT NAME>\"\n",
    "DEPLOYMENT_NAME = 'data-preprocessor'\n",
    "DEPLOYMENT_VERSION = 'v1'\n",
    "\n",
    "# Import all necessary libraries\n",
    "import shutil\n",
    "import os\n",
    "import ubiops\n",
    "\n",
    "client = ubiops.ApiClient(ubiops.Configuration(api_key={'Authorization': API_TOKEN}, \n",
    "                                               host='https://api.ubiops.com/v2.1'))\n",
    "api = ubiops.CoreApi(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a training pipeline\n",
    "\n",
    "Our training pipeline will consist of two steps: preprocessing the data, and training a model.\n",
    "For each of these two steps we will create a separate deployment in UbiOps. This way the processing step can be reused later in the deployment pipeline (or in other pipelines) and each block will be scaled separately, increasing speed.\n",
    "\n",
    "### Preprocessing the data\n",
    "In the cell below the deployment.py of the preprocessing block is loaded. In the request function you can see that the deployment will clean up the data for further use and output that back in the form of two csv files. \n",
    "The deployment has the following input:\n",
    "- data: a csv file with the training data or with real data\n",
    "- training: a boolean indicating whether we using the data for training or not. In the case this boolean is set to true the target outcome is split of of the training data.\n",
    "\n",
    "The use of the boolean input \"training\" allows us to reuse this block later in a production pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load preprocessing_package/deployment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a deployment and a deployment version for the package in the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    description='Clean up data',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='data',\n",
    "            data_type='blob',\n",
    "        ),\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='training',\n",
    "            data_type='bool',\n",
    "        )\n",
    "    ],\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='cleaned_data',\n",
    "            data_type='blob'\n",
    "        ),\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='target_data',\n",
    "            data_type='blob'\n",
    "        )\n",
    "    ],\n",
    "    labels={'demo': 'scikit-deployment'}\n",
    ")\n",
    "\n",
    "api.deployments_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=deployment_template\n",
    ")\n",
    "\n",
    "# Create the version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    language='python3.6',\n",
    "    memory_allocation=512,\n",
    "    minimum_instances=0,\n",
    "    maximum_instances=1,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # we don't need request storage in this example\n",
    ")\n",
    "\n",
    "api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    data=version_template\n",
    ")\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive('preprocessing_package', 'zip', '.', 'preprocessing_package')\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "file_upload_result =api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='preprocessing_package.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model will now have been deployed to your UbiOps environment. Go ahead and take a look in the UI in the tab deployments to see it for yourself. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing\n",
    "\n",
    "Now that we have the preprocessing deployment in UbiOps, we need a deployment that can take the output of the preprocessing step and train a KNN model on it. The code for this is in the \"training_package\" directory and can be seen in the next cell. We are going to perform the same steps as above to deploy this code in UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load training_package/deployment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to deploy this step to UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_template_t = ubiops.DeploymentCreate(\n",
    "    name='model-training',\n",
    "    description='Trains a KNN model',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='cleaned_data',\n",
    "            data_type='blob',\n",
    "        ),\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='target_data',\n",
    "            data_type='blob',\n",
    "        )\n",
    "    ],\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='trained_model',\n",
    "            data_type='blob'\n",
    "        ),\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='model_score',\n",
    "            data_type='double'\n",
    "        )\n",
    "    ],\n",
    "    labels={'demo': 'scikit-deployment'}\n",
    ")\n",
    "\n",
    "api.deployments_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=deployment_template_t\n",
    ")\n",
    "\n",
    "# Create the version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    language='python3.6',\n",
    "    memory_allocation=512,\n",
    "    minimum_instances=0,\n",
    "    maximum_instances=1,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # we don't need request storage in this example\n",
    ")\n",
    "\n",
    "api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name='model-training',\n",
    "    data=version_template\n",
    ")\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive('training_package', 'zip', '.', 'training_package')\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "file_upload_result =api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name='model-training',\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='training_package.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if both deployments, preprocessing and training, are available for further use. Only once the models are built and ready can we use them in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "status1 = 'building'\n",
    "status2 = 'building'\n",
    "while (status1 != 'available' and 'failed' not in status1) or (status2 != 'available' and 'failed' not in status2) :    \n",
    "    version_status1 = api.deployment_versions_get(       \n",
    "        project_name=PROJECT_NAME,        \n",
    "        deployment_name=DEPLOYMENT_NAME,        \n",
    "        version=DEPLOYMENT_VERSION    \n",
    "    )    \n",
    "    status1 = version_status1.status\n",
    "    version_status2 = api.deployment_versions_get(       \n",
    "        project_name=PROJECT_NAME,        \n",
    "        deployment_name='model-training',        \n",
    "        version=DEPLOYMENT_VERSION    \n",
    "    )   \n",
    "    status2 = version_status2.status\n",
    "    sleep(1)\n",
    "    \n",
    "print(status1)\n",
    "print(status2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a training pipeline\n",
    "\n",
    "So right now we have two deployments: one cleaning up the input data and one using that data for training a model. We want to tie these two blocks together to create a workflow. We can use pipelines for that. Let's create a pipeline that takes the same input as the preprocessing block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline_name = \"training-pipeline\"\n",
    "\n",
    "pipeline_template = ubiops.PipelineCreate(\n",
    "    name=training_pipeline_name,\n",
    "    description='A simple pipeline that cleans up data and trains a KNN model on it.',\n",
    "    input_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='data',\n",
    "            data_type='blob',\n",
    "        ),\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='training',\n",
    "            data_type='bool',\n",
    "        )\n",
    "    ],\n",
    "    output_type='structured',\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='trained_model',\n",
    "            data_type='blob'\n",
    "        ),\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='model_score',\n",
    "            data_type='double'\n",
    "        )\n",
    "    ],\n",
    "    labels={'demo': 'scikit-deployment'}\n",
    ")\n",
    "\n",
    "api.pipelines_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=pipeline_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline_version = DEPLOYMENT_VERSION\n",
    "\n",
    "pipeline_template = ubiops.PipelineVersionCreate(\n",
    "    version=training_pipeline_version,\n",
    "    request_retention_mode='none' # we don't need request storage for this example\n",
    ")\n",
    "\n",
    "api.pipeline_versions_create(\n",
    "    project_name=PROJECT_NAME, pipeline_name=training_pipeline_name, data=pipeline_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a pipeline, now we just need to add our two components to it and connect it.\n",
    "\n",
    "**IMPORTANT**: If you get an error like: \"error\":\"Version is not available: The version is currently in the building stage\"\n",
    "Your model is not yet available and still building. \n",
    "Check in the UI if your model is ready and then rerun the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the preprocessing deployment\n",
    "object_template = ubiops.PipelineVersionObjectCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    reference_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION\n",
    ")\n",
    "api.pipeline_version_objects_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    pipeline_name=training_pipeline_name,\n",
    "    version=training_pipeline_version,\n",
    "    data=object_template\n",
    ")\n",
    "\n",
    "# Adding the training deployment\n",
    "object_template2 = ubiops.PipelineVersionObjectCreate(\n",
    "    name='model-training',\n",
    "    reference_name='model-training',\n",
    "    version=DEPLOYMENT_VERSION\n",
    ")\n",
    "api.pipeline_version_objects_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    pipeline_name=training_pipeline_name,\n",
    "    version=training_pipeline_version,\n",
    "    data=object_template2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the components\n",
    "\n",
    "# First connecting start --> preprocessor\n",
    "attachment_template1 = ubiops.AttachmentsCreate(\n",
    "    destination_name=DEPLOYMENT_NAME,\n",
    "    sources=[\n",
    "        ubiops.AttachmentSourcesCreate(\n",
    "            source_name='pipeline_start',\n",
    "            mapping=[\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='data',\n",
    "                    destination_field_name='data'\n",
    "                ),\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='training',\n",
    "                    destination_field_name='training'\n",
    "                )]\n",
    "        )]\n",
    ")\n",
    "\n",
    "api.pipeline_version_object_attachments_create(\n",
    "    project_name=PROJECT_NAME, \n",
    "    pipeline_name=training_pipeline_name, \n",
    "    version=training_pipeline_version,\n",
    "    data=attachment_template1\n",
    ")\n",
    "\n",
    "# Connection preprocessor --> model-training\n",
    "attachment_template2 = ubiops.AttachmentsCreate(\n",
    "    destination_name='model-training',\n",
    "    sources=[\n",
    "        ubiops.AttachmentSourcesCreate(\n",
    "            source_name=DEPLOYMENT_NAME,\n",
    "            mapping=[\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='cleaned_data',\n",
    "                    destination_field_name='cleaned_data'\n",
    "                ),\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='target_data',\n",
    "                    destination_field_name='target_data'\n",
    "                )]\n",
    "        )]\n",
    ")\n",
    "\n",
    "\n",
    "api.pipeline_version_object_attachments_create(\n",
    "    project_name=PROJECT_NAME, \n",
    "    pipeline_name=training_pipeline_name,\n",
    "    version=training_pipeline_version, \n",
    "    data=attachment_template2\n",
    ")\n",
    "\n",
    "# Connection model-training -> pipeline end\n",
    "attachment_template2 = ubiops.AttachmentsCreate(\n",
    "    destination_name='pipeline-end',\n",
    "    sources=[\n",
    "        ubiops.AttachmentSourcesCreate(\n",
    "            source_name='model-training',\n",
    "            mapping=[\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='trained_model',\n",
    "                    destination_field_name='trained_model'\n",
    "                ),\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='model_score',\n",
    "                    destination_field_name='model_score'\n",
    "                )]\n",
    "        )]\n",
    ")\n",
    "\n",
    "\n",
    "api.pipeline_version_object_attachments_create(\n",
    "    project_name=PROJECT_NAME, \n",
    "    pipeline_name=training_pipeline_name,\n",
    "    version=training_pipeline_version, \n",
    "    data=attachment_template2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline done!\n",
    "If you check in your UbiOps account under pipeline you will find a training-pipeline with our components in it and connected. Let's make a request to it. You can also make a request in the UI with the \"create direct request button\".\n",
    "\n",
    "this might take a while since the models will need a cold start as they have never been used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline_name = \"training-pipeline\"\n",
    "\n",
    "blob = api.blobs_create(project_name=PROJECT_NAME, file='diabetes.csv', blob_ttl=1000)\n",
    "\n",
    "data = {'data': blob.id, 'training': True}\n",
    "pipeline_result = api.pipeline_version_requests_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    pipeline_name=training_pipeline_name,\n",
    "    version=training_pipeline_version,\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print(pipeline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's keep the blobid of the trained model safe for further use:\n",
    "# We will check the most recent blobs in our environment and look for the trained model one.\n",
    "# The trained model is kept in a joblib file called knn.joblib\n",
    "blobs_list = api.blobs_list(project_name = PROJECT_NAME)\n",
    "trained_model_blob = None\n",
    "for blob in blobs_list:\n",
    "    if blob.filename == 'knn.joblib':\n",
    "        trained_model_blob = str(blob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with the trained model\n",
    "\n",
    "Our model is trained and ready. Now we still need to deploy a predictor to UbiOps that uses this model for predicting. \n",
    "\n",
    "I already have the code and the requirements ready that need to be deployed to UbiOps. However, the joblib file is still missing in this folder. We dont want to manually download the joblib file output from the training pipeline, but automatically put it in the deployment package for the predictor. After that we can zip up the folder and push it to UbiOps like we did with the previous two packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load predictor_package/deployment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to download the trained model joblib and put it in the predictor package directory\n",
    "base_directory = os.path.dirname(os.path.abspath(\"scikit-deployment\"))\n",
    "\n",
    "with api.blobs_get(project_name=PROJECT_NAME, blob_id=trained_model_blob) as response:\n",
    "    output_path = os.path.join(base_directory, \"predictor_package\", response.getfilename())\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(response.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to zip the deployment package\n",
    "shutil.make_archive('predictor_package', 'zip', '.', 'predictor_package')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the KNN model\n",
    "The folder is ready, now we need to make a deployment in UbiOps. Just like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name='knn-model',\n",
    "    description='KNN model for diabetes prediction',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='data',\n",
    "            data_type='blob',\n",
    "        ),\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='data_cleaning_artefact',\n",
    "            data_type='blob',\n",
    "        )\n",
    "    ],\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='prediction',\n",
    "            data_type='blob'\n",
    "        ),\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='predicted_diabetes_instances',\n",
    "            data_type='int'\n",
    "        )\n",
    "    ],\n",
    "    labels={'demo': 'scikit-deployment'}\n",
    ")\n",
    "\n",
    "api.deployments_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=deployment_template\n",
    ")\n",
    "\n",
    "# Create the version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    language='python3.6',\n",
    "    memory_allocation=512,\n",
    "    minimum_instances=0,\n",
    "    maximum_instances=1,\n",
    "    maximum_idle_time=1800, # = 30 minutes\n",
    "    request_retention_mode='none' # we don't need request storage in this example\n",
    ")\n",
    "\n",
    "api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name='knn-model',\n",
    "    data=version_template\n",
    ")\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "file_upload_result =api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name='knn-model',\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file='predictor_package.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the deployment is ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 'building'\n",
    "while status != 'available' and 'failed' not in status:    \n",
    "    version_status = api.deployment_versions_get(       \n",
    "        project_name=PROJECT_NAME,        \n",
    "        deployment_name='knn-model',        \n",
    "        version=DEPLOYMENT_VERSION    \n",
    "    )    \n",
    "    status = version_status.status\n",
    "    sleep(1)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the production pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_pipeline_name = \"production-pipeline\"\n",
    "\n",
    "pipeline_template = ubiops.PipelineCreate(\n",
    "    name=prod_pipeline_name,\n",
    "    description=\"A simple pipeline that cleans up data and let's a KNN model predict on it.\",\n",
    "    input_type='structured',\n",
    "    input_fields=[\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='data',\n",
    "            data_type='blob',\n",
    "        ),\n",
    "        ubiops.DeploymentInputFieldCreate(\n",
    "            name='training',\n",
    "            data_type='bool',\n",
    "        )\n",
    "    ],\n",
    "    output_type='structured',\n",
    "    output_fields=[\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='prediction',\n",
    "            data_type='blob'\n",
    "        ),\n",
    "        ubiops.DeploymentOutputFieldCreate(\n",
    "            name='predicted_diabetes_instances',\n",
    "            data_type='int'\n",
    "        )\n",
    "    ],\n",
    "    labels={'demo': 'scikit-deployment'}\n",
    ")\n",
    "\n",
    "api.pipelines_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    data=pipeline_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_pipeline_version = DEPLOYMENT_VERSION\n",
    "\n",
    "pipeline_template = ubiops.PipelineVersionCreate(\n",
    "    version=prod_pipeline_version\n",
    "    request_retention_mode='none' # we don't need request storage in this example\n",
    ")\n",
    "\n",
    "api.pipeline_versions_create(project_name=PROJECT_NAME, pipeline_name=prod_pipeline_name, data=pipeline_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the preprocessing and the predicting components and connecting them.\n",
    "\n",
    "**IMPORTANT**: If you get an error like: \"error\":\"Version is not available: The version is currently in the building stage\"\n",
    "Your model is not yet available and still building. \n",
    "Check in the UI if your model is ready and then rerun the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the preprocessing deployment\n",
    "object_template = ubiops.PipelineVersionObjectCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    reference_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION\n",
    ")\n",
    "api.pipeline_version_objects_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    pipeline_name=prod_pipeline_name,\n",
    "    version=prod_pipeline_version,\n",
    "    data=object_template\n",
    ")\n",
    "\n",
    "# Adding the KNN deployment\n",
    "object_template2 = ubiops.PipelineVersionObjectCreate(\n",
    "    name='knn-model',\n",
    "    reference_name='knn-model',\n",
    "    version=DEPLOYMENT_VERSION\n",
    ")\n",
    "api.pipeline_version_objects_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    pipeline_name=prod_pipeline_name,\n",
    "    version=prod_pipeline_version,\n",
    "    data=object_template2\n",
    ")\n",
    "\n",
    "# Connecting the components\n",
    "# First connecting start --> preprocessor\n",
    "attachment_template1 = ubiops.AttachmentsCreate(\n",
    "    destination_name=DEPLOYMENT_NAME,\n",
    "    sources=[\n",
    "        ubiops.AttachmentSourcesCreate(\n",
    "            source_name='pipeline_start',\n",
    "            mapping=[\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='data',\n",
    "                    destination_field_name='data'\n",
    "                ),\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='training',\n",
    "                    destination_field_name='training'\n",
    "                )]\n",
    "        )]\n",
    ")\n",
    "\n",
    "api.pipeline_version_object_attachments_create(\n",
    "    project_name=PROJECT_NAME, \n",
    "    pipeline_name=prod_pipeline_name, \n",
    "    version=prod_pipeline_version,\n",
    "    data=attachment_template1\n",
    ")\n",
    "\n",
    "# Connection preprocessor --> KNN model\n",
    "attachment_template2 = ubiops.AttachmentsCreate(\n",
    "    destination_name='knn-model',\n",
    "    sources=[\n",
    "        ubiops.AttachmentSourcesCreate(\n",
    "            source_name=DEPLOYMENT_NAME,\n",
    "            mapping=[\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='cleaned_data',\n",
    "                    destination_field_name='data'\n",
    "                ),\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='target_data',\n",
    "                    destination_field_name='data_cleaning_artefact'\n",
    "                )]\n",
    "        )]\n",
    ")\n",
    "\n",
    "\n",
    "api.pipeline_version_object_attachments_create(\n",
    "    project_name=PROJECT_NAME, \n",
    "    pipeline_name=prod_pipeline_name, \n",
    "    version=prod_pipeline_version,\n",
    "    data=attachment_template2\n",
    ")\n",
    "\n",
    "# Connection KNN model -> pipeline end\n",
    "attachment_template3 = ubiops.AttachmentsCreate(\n",
    "    destination_name='pipeline_end',\n",
    "    sources=[\n",
    "        ubiops.AttachmentSourcesCreate(\n",
    "            source_name='knn-model',\n",
    "            mapping=[\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='prediction',\n",
    "                    destination_field_name='prediction'\n",
    "                ),\n",
    "                ubiops.AttachmentFieldsCreate(\n",
    "                    source_field_name='predicted_diabetes_instances',\n",
    "                    destination_field_name='predicted_diabetes_instances'\n",
    "                )]\n",
    "        )]\n",
    ")\n",
    "\n",
    "\n",
    "api.pipeline_version_object_attachments_create(\n",
    "    project_name=PROJECT_NAME, \n",
    "    pipeline_name=prod_pipeline_name, \n",
    "    version=prod_pipeline_version,\n",
    "    data=attachment_template3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a request and exploring further\n",
    "You can go ahead to the Web App and take a look in the user interface at what you have just built. If you want you can create a request to the production pipeline using the \"dummy_data_for_predicting.csv\" and setting the \"training\" input to \"False\". The dummy data is just the diabetes data with the Outcome column chopped of. \n",
    "\n",
    "So there we have it! We have made a training pipeline and a production pipeline using the scikit learn library. You can use this notebook to base your own pipelines on. Just adapt the code in the deployment packages and alter the input and output fields as you wish and you should be good to go. \n",
    "\n",
    "For any questions, feel free to reach out to us via the customer service portal: https://ubiops.atlassian.net/servicedesk/customer/portals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}